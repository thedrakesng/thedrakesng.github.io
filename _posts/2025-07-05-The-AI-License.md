---
layout: single
title: "The AI License: Why Algorithms Can Replace Your Doctor (or already have)"
date: 2025-07-05
tags: Ideas
categories: Ideas
author: Yongjun Song
published: true
---

The question "Will AI take my job?" has become a familiar hum of anxiety in the modern workforce. For many, the ultimate safe harbor has always been a professional license—a shield of education, ethics, and law that separates a professional from a hobbyist. But as algorithms begin to perform tasks in medicine, law, and engineering, the shield is starting to look less like a solid barrier and more like a permeable membrane.

While headlines often focus on replacement, the current reality is one of **augmentation**. For now, in most licensed jobs, AI is a powerful assistant, not a successor. In law, it reviews thousands of contracts for key clauses, but a human lawyer builds the case strategy. In medicine, it flags anomalies in an MRI scan, but a human radiologist makes the final diagnosis and consults with the patient.

But how long will AI remain as assistants? To understand when—or if—AI will fully replace licensed professionals, we must first ignore the technology and ask a more fundamental question: **Why do licenses exist?**

The answer rests on three foundational pillars.

### The Three Pillars of Professional Licensing

A license is a contract between a professional, the public, and a governing body. It exists to manage high-stakes risk in situations where the average person cannot judge the quality of a service for themselves.

1.  **Safety & Public Welfare (The "Do No Harm" Pillar):** The primary goal is to protect the public from significant harm—physical, financial, or legal—that could result from incompetence. This is why surgeons must complete years of residency, pilots spend thousands of hours in simulators, and structural engineers have their designs peer-reviewed. The system is designed to minimize the probability of catastrophic failure, whether it's a misdiagnosed illness, a faulty bridge, or a mishandled legal case.

2.  **Accountability & Recourse (The "Who's Responsible" Pillar):** If harm occurs, there must be a clear, identifiable person or entity to hold responsible. A license can be suspended or revoked, and a professional can be sued for malpractice. This system of personal, high-stakes accountability provides a powerful incentive for careful, ethical conduct and gives the public a clear path for recourse when things go wrong.

3.  **Trust & Information Asymmetry (The "Knowledge Gap" Pillar):** You don't have the specialized knowledge to vet your surgeon's technique, the structural calculations of an engineer, or a lawyer's interpretation of case law. The license is a trusted, third-party signal that says, "This person has met a verified standard." It bridges the vast knowledge gap between the expert and the client, allowing the public to engage with professionals with a baseline of confidence.

---

### The Real Requirements for an AI to Replace a Professional

For an algorithm to truly replace a licensed professional, it must do more than just perform a task with high accuracy. It must be integrated into a new framework that fully satisfies these three pillars.

| Licensing Pillar | Corresponding AI Requirement | What It Means in Practice |
| :--- | :--- | :--- |
| **1.Safety** | **Provable & Continuous Reliability** | The AI can't just pass a one-time test. It needs a system for **continuous, real-time verification** of its performance against real-world outcomes. Its safety and efficacy data must be transparent and auditable by independent bodies (think of an FDA for algorithms), proving it consistently outperforms the human baseline, especially in unexpected "edge case" scenarios. |
| **2.Accountability** | **A New Framework for Legal & Financial Liability** | Who do you sue for malpractice? A specific, legally recognized entity must be designated as the "license holder." This entity—whether the developer or a certified operator—must be **insurable for malpractice** at a massive scale and subject to a clear process for having its "license" to operate revoked by regulators. Without a clear line of responsibility, there is no recourse. |
| **3.Trust** | **Radical Transparency & Explainability (XAI)** | The AI cannot be a "black box." It must be able to **explain its reasoning** for any high-stakes decision in a way that is understandable to both regulators and the public it serves. This isn't just a matter of logging outputs; it's about generating a logical, auditable rationale. This is the only way to build trust and bridge the knowledge gap when the "professional" is a piece of code. |

### The Transition in Action: From Driver's License to System Certification

This shift is already happening in a visible way with autonomous vehicles. Companies like Waymo are not just building a better cruise control; they are building a system designed to meet these three pillars.

*   **Safety:** They are accumulating billions of miles of data to prove their system is safer than a human driver.
*   **Accountability:** Liability is shifting from an individual driver to the corporation that owns and operates the fleet.
*   **Trust:** The final frontier is public acceptance, which is why rollouts are slow, heavily monitored, and geographically limited.

The "driver's license" is slowly being transferred from a person to a certified system.

### In the Medical Field: The AI Diagnostic Assistant

EyeArt, an autonomous AI system that screens for diabetic retinopathy, is no longer just a radiology aide. In 2020 it became the first FDA-cleared algorithm allowed to issue a clinical diagnosis without a physician’s sign-off, and by 2025 it has been validated on more than half a million patient visits worldwide. This is not a narrow pilot—it’s an early prototype of what a licensed, accountable “AI professional” looks like. 

*   **Safety:** Prospective trials show >95 % sensitivity and clinically acceptable specificity. Post-market surveillance requirements mean every exam is logged and tracked for drift, creating a continuous audit trail of real-world performance. 
*   **Accountability:** Eyenuk, the legal manufacturer, carries regulatory responsibility under FDA and MDSAP audits.
*   **Trust:** Each report includes the retinal images with heat-map overlays that highlight the lesions driving the decision, offering clinicians and patients a transparent rationale.

### In Finance: Automated Underwriting and Valuation

Automated systems like Fannie Mae's Desktop Underwriter (DU) have streamlined finance for decades, but they remain tools for augmentation, not licensed actors.

*   **Safety:** These systems enforce consistency for standard applications, reducing simple errors. However, they are rigid and can fail spectacularly with unusual data or novel market conditions, requiring a human expert to prevent systemic risk.
*   **Accountability:** The underwriter's signature on a loan or an appraiser's on a valuation is a legally binding act of professional responsibility. The algorithm's recommendation carries no such weight or legal standing.
*   **Trust:** The financial system operates on trusted, legally recognized signals of approval. The license is that signal. The market trusts the professional's judgment to stand behind a financial decision, not the machine's output.

### Conclusion: The Replacement is a matter(s) of... [ ]

The prevailing narrative from Silicon Valley is that the future is one of collaboration. We are told that AI will handle the repetitive tasks, freeing up human professionals to focus on higher-level strategy, ethics, and communication.

But this comforting vision overlooks the true lesson of the three pillars. Safety, Accountability, and Trust are not permanent barriers; they are engineering problems. They represent the benchmark that an AI must meet to acquire a license. The work being done with autonomous vehicles shows us that a roadmap to meeting these benchmarks already exists.

Geoffrey Hinton, a godfather of modern AI, noted that before the Industrial Revolution, physical strength was a human bottleneck. Technology made that bottleneck irrelevant. Today, intelligence is the bottleneck. To believe that AI will stop at being a mere 'assistant' is to assume this revolution will be different from all others.

As the post said the transition is happening. Autonomous driving is replacing UBER drivers. EyeArt has replaced the fundus examination and it has already shifted two of the three pillars (safety and accountability). Trust is being earned through open transparency rather than bedside manner. That trajectory—from tool ➜ autonomous system ➜ licensed entity—is exactly the roadmap every high-stakes profession will face. The logic is clear: if an algorithm can satisfy the pillars better, cheaper, or at larger scale than a human, the “license” will migrate. A professional license is not an eternal shield. Now it is only a matter of time, necessity, regulation, and so on.

The 'so on' seems quiet long. 

In the next post, I’ll examine the conditions required for this replacement to occur.